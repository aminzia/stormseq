<!DOCTYPE html>
<html lang="en">
 <head>
   <meta charset="utf-8">
   <title>STORMSeq</title>
   <meta name="viewport" content="width=device-width, initial-scale=1.0">
   <meta name="description" content="STORMSeq Main Page">
   <meta name="author" content="Konrad Karczewski">
   <link href="css/bootstrap.css" rel="stylesheet">
   <link href="css/bootstrap-responsive.css" rel="stylesheet">
   <link href="css/stormseq.css" rel="stylesheet">
   <script src="js/jquery-1.7.2.min.js"></script>
   <script src="js/bootstrap.js"></script>
   <style>
     body {
       padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
     }
   </style>
   <link href="css/bootstrap-responsive.css" rel="stylesheet">
 </head>
 <body>
  <div class="navbar navbar-fixed-top">
    <div class="navbar-inner">
      <div class="container">
        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </a>
        <a class="brand" href="index.html">STORMSeq</a>
        <div class="nav-collapse">
          <ul class="nav">
            <li><a href="index.html">Home</a></li>
            <li><a href="about.html">About</a></li>
            <li class="active"><a href="use.html">How to Use</a></li>
            <li><a href="contact.html">Contact</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>
  </div>
  <div class="container">
   <div class="page-header">
    <h1>Map reads and call variants with STORMSeq!</h1>
   </div>
   <div class="row">
    <div class="span12">
     <h2>Requirements</h2>
     <li>
      An Amazon AWS account.
     </li>
     <li>
      Paired-end short read data in FASTQ format.
     </li>
     <li>
      Some time and patience. High quality data can take time.
     </li>
     <br/>
     <p>
     That's it! You'll also need a way to securely upload the reads and other files.
     We recommend <a href="http://cyberduck.ch/">Cyberduck</a> for Mac OS X and Windows.
     Linux users will probably already know how to SFTP.
     </p>
     <h2>How to use STORMSeq</h2>
      <h3>0. Set up an Amazon AWS account and enable EC2 and S3.</h3>
       <li>Your telephone number and billing information will be verified with Amazon, which may take some time (typically a few minutes, but could take longer).</li>
       
      <h3>1. Go to the EC2 Management Console.</h3>
       <li>You can do this by going to <a href="http://aws.amazon.com">AWS page</a> and finding the AWS Management Console in the top right.</li>
       <br/><br/>
       <img src='img/1.1_console.png' width='80%' />
       <br/><br/>
       <li>In the AWS console, click on the EC2 link.</li>
       <br/><br/>
       <img src='img/1.2_ec2.png' width='80%' />
       <br/><br/>
       
      <h3>2. Start a new EC2 instance to start the webserver.</h3>
       <li>You are now on the EC2 console, where you can see all your running resources in the right panel.</li>
       <li><b>IMPORTANT:</b> Note your region in the top left. Please choose US East (Virginia) for now.</li>
       <li>Click instances in the left panel</li>
       <img src='img/2.1_ec2_console.png' class='full-window' />
       <br/><br/>
       <li>Click "Launch Instance" and click Continue through the Classic Wizard</li>
       <img src='img/2.2_ec2_instances.png' class='full-window' />
       <br/><br/>
       <li>Click "Community AMIs"</li>
       <img src='img/2.3_new_instance.png' class='dialog' />
       <br/><br/>
       <li>Search for the STORMSeq AMI (ami-XXXXXXX) and select it</li>
       <img src='img/2.4_stormseq_ami.png' class='dialog' />
       <br/><br/>
       <li>Select your instance type and availability zone</li>
       <li>Since this is just the webserver, the instance can be of any type, including Micro.</li>
       <li>Please select us-east-1b for the availability zone.</li>
       <li>Click continue</li>
       <li>Advanced: You may request a spot instance at this stage, but note that when setting the "stormseq" tag later,
       Amazon AWS currently has a bug where it will forget the tag and you must go back and add it later.</li>
       <img src='img/2.5_instance_type.png' class='dialog' />
       <br/><br/>
       <li>Click continue through "Advanced Instance Options" and "Storage Device Configuration" leaving the default options.</li>
       <li><b>Important!:</b> In the tags interface, name the instance "stormseq" for the software to identify the server.</li>
       <li>Click continue.</li>
       <img src='img/2.6_name_instance.png' class='dialog' />
       <br/><br/>
       <li>Create a key pair so that you can login to the system to upload your files. Name this file anything memorable, and remember where you saved it.</li>
       <li>We will refer to this key the "Key Pair" file (not to be confused with the later "Private Key" and "Certificate" files)</li>
       <li>If this is not your first time using STORMSeq, you can skip this step if you still have the key pair file saved on your computer.</li>
       <img src='img/2.7_create_key.png' class='dialog' />
       <br/><br/>
       <li>Create a new security group named "stormseq" as shown below. Verify that the SSH service is listed as shown.</li>
       <li>(If it is not, create a new rule selecting SSH from the dropdown box and click "Apply rule")</li>
       <li>If this is not your first time using STORMSeq, you can skip this step if the "stormseq" security group still exists.</li>
       <li>Click Continue</li>
       <img src='img/2.8_create_security_group.png' class='dialog' />
       <br/><br/>
       <li>Your instance is ready! Click Launch.</li>
       <br/><br/>

      <h3>3. Create a new volume where we will upload our data.</h3>
       <li>Back at the EC2 console, click Volumes in the left panel</li>
       <img src='img/3.1_volumes.png' class='full-window' />
       <br/><br/>
       <li>Create a volume of suitable size in the same availability zone (us-east-1b).</li>
       <li>The size must be large enough for temporary files created by the software, so we recommend the following:</li>
       <ul>
        <li>If you are uploading raw FASTQ files, we recommend at least 10X the total upload size (if you upload 10 GB of *.fq, please select at least 100 GB)</li>
        <li>If you are uploading gzipped FASTQ files, we recommend at least 25X the total upload size (if you upload 2 GB of *.fq.gz, please select at least 50 GB)</li>
       </ul>
       <li><i>Note: More can't hurt here, and Amazon storage is fairly cheap (at present, $0.10 per GB-month, pro-rated for less time).</i></li>
       <li>Click "Yes, create"</li>
       <img src='img/3.2_create_volume.png' class='small-dialog' />
       <br/><br/>
       <li>As with the instance, we are going to create a tag for our volume so that the software can find our data.</li>
       <li>Click "Add/Edit Tags" as shown here</li>
       <img src='img/3.3_tag_volume.png' class='full-window' />
       <br/><br/>
       <li>In the Value field (in the row whose Key is Name, as shown), enter "stormseq_data" and click "Save Tags"</li>
       <img src='img/3.4_create_tag.png' class='dialog' />
       <br/><br/>
       
      <h3>4. Upload security files to the newly created instance.</h3>
       <li>Now, we need to get our security credentials for the server to be able to start more servers and run our mapping jobs.</li>
       <li>In the top right corner of the Amazon window, click your name and then Security Credentials</li>
       <img src='img/4.1_create_credentials.png' class='small-dialog' />
       <br/><br/>
       <li>Scroll down and select "X.509 Certificates" and then "Create a new Certificate"</li>
       <img src='img/4.2_create_credential_files.png' class='dialog' />
       <br/><br/>
       <li>When they have been created, download both of these files ("Private Key" and "Certificate") and note where they are saved. Do not rename them.</li>
       <img src='img/4.3_download_creds.png' class='small-dialog' />
       <br/><br/>
       <li>Close the window/tab to return to the EC2 console and click Instances.</li>
       <li>By now, we should notice our server up and running! Click the instance itself and copy the address (ec2-XX-XX-XX-XX.compute-1.amazonaws.com).</li>
       <li>Point your web browser to this address and you should see a landing page.</li>
       <img src='img/4.4_landing_page.png' class='dialog' />
       <br/><br/>
       <li>Upload the "Private Key" and "Certificate" files by clicking the link ("here") on the landing page, or using an SFTP client (username: root, no password).</li>
       <li>Use the "Key Pair" file as the public key authentication. On Cyberduck, this means checking the box below and navigating to the "Key Pair" file from before.</li>
       <img src='img/4.5_sftp_upload.png' class='small-dialog' />
       <br/><br/>
       <li>Drag and drop the "Private Key" (pk-*.pem) and "Certificate" (cert-*.pem) files onto the client to upload them.</li>
      
      <h3>5. Upload your reads!</h3>
       <li>We're almost there! Now in a little bit of server magic, after a few minutes, the landing page from before should automatically switch to the secure version of the site.</li>
       <li>Your browser will likely throw a warning that the certificate cannot be trusted.
       This is because the server signed it itself. It is safe to proceed.</li>
       <img src='img/5.0_ssl_cert.png' class='full-window' />
       <br/><br/>
       <li>Once it does, we can upload our reads by clicking the link on the page (which will open a link to the same server to the /mnt/stormseq_data directory).</li>
       <img src='img/5.1_main_page.png' class='full-window' />
       <li>Login using your public key ("Key Pair" file) as before, and drag and drop your reads to this directory. Reads can be *.fq, *.fastq, or *.fq.gz (gzipped).</li>
       <li>This may take some time depending on how much data you have (may take overnight for high coverage genomes). Go grab a drink.</li>
       <br/>
      
      <h3>6. Get final security credentials</h3>
       <li>While we're waiting, we can get the last of the security credentials needed. As before, click your name in the top right corner, and then Security Credentials</li>
       <li>Click "Create Access Key" to generate a new access key id and secret key</li>
       <li>Note: You can use the one that is already there, but for maximum security in this example, we will create a new one that you can delete it later.</li>
       <img src='img/6.1_get_access_keys.png' class='small-dialog' />
       <br/><br/>
       <li>Copy your account number, as well as the "Access Key ID" and "Secret Access Key" (click "Show" to see this) into the relevant fields on the STORMSeq start page.</li>
       <img src='img/6.2_access_keys.png' class='small-dialog' />
       <br/><br/>
      
      <h3>7. Create S3 bucket for our results</h3>
       <li>Finally, we'll create a S3 persistent storage bucket for our results (BAM and VCF files).</li>
       <li>Back at the AWS Management Console, click the S3 link.</li>
       <img src='img/7.1_s3.png' class='small-dialog' />
       <br/><br/>
       <li>Click "Create Bucket" and name the bucket (it must not share a name with any other person's bucket, so you may need to get creative with naming).</li>
       <li>Copy this name into the STORMSeq start page in the S3 Bucket field.</li>
       <img src='img/7.2_buckets.png' class='small-dialog' />
       <br/><br/>
       
      <h3>8. Set your parameters and begin processing!</h3>
       <li>Return to your STORMSeq start page (ec2-XX-XX-XX-XX.compute-1.amazonaws.com) and poke around!</li>
       <li>In particular, note the Amazon EC2 Advanced Options link, where you can set the prices for bidding on compute time to save money
       (more information can be found <a href="http://aws.amazon.com/ec2/spot-instances/#0">here</a>).
       Note that there are currently no failure modes. If your jobs are cancelled due to a low bid, they cannot be resumed, and will need to be set up from scratch).</li>
       <li><em>Wait until your reads are finished uploading</em>, then click "Verify Amazon Data and Files" for the software to verify your upload on the server.
       This may take a few minutes depending on a number of factors, including the size of your upload.</li>
       <li>When this completes, the "GO!" button will be active, which you can click to start the pipeline.</li>
       <li>That's it! Your progress will be updated every few minutes and results will be available below.</li>
    </div>
   </div>
   <footer>
    <p>&copy; Karczewski et al., 2012</p>
   </footer>
  </div> <!-- /container -->
 </body>
</html>